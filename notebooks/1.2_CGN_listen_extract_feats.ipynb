{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from GSSP_utils.path_conf import cgn_root_dir, cgn_ort_path, loc_data_dir\n",
    "from GSSP_utils.cgn import listen_to_audio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm.auto import tqdm\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "from uuid import uuid4\n",
    "\n",
    "pd.options.display.max_rows = 80\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import opensmile\n",
    "from multiprocess import Pool\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "func_gemaps = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.GeMAPSv01b,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged orthographic + recording + speaker metadata\n",
    "df_cgn_metadata = pd.read_parquet(loc_data_dir / 'df_cgn_ort_rec_speaker.parquet')\n",
    "df_cgn_metadata['uuid'] = [str(uuid4()) for _ in range(len(df_cgn_metadata))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will only use the components of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_components = ['b', 'o'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>#segments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_type</th>\n",
       "      <th>dop</th>\n",
       "      <th>domain</th>\n",
       "      <th>sex</th>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">ttb</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">unscripted</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">private</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">female</th>\n",
       "      <th>Flanders</th>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">male</th>\n",
       "      <th>Flanders</th>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">tto</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">scripted</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">private</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">female</th>\n",
       "      <th>Flanders</th>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">male</th>\n",
       "      <th>Flanders</th>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 #segments\n",
       "text_type dop        domain  sex    country               \n",
       "ttb       unscripted private female Flanders           771\n",
       "                                    Netherlands        191\n",
       "                             male   Flanders           576\n",
       "                                    Netherlands        176\n",
       "tto       scripted   private female Flanders           826\n",
       "                                    Netherlands         58\n",
       "                             male   Flanders           673\n",
       "                                    Netherlands         86"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cgn_metadata[\n",
    "    (df_cgn_metadata.duration_s > 19) &\n",
    "    (df_cgn_metadata.component.isin(valid_components)) \n",
    "].groupby(\n",
    "    ['text_type', 'dop', 'domain', 'sex','country']\n",
    ").size().rename('#segments').to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## listen to the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listen_to_audio(\n",
    "#     df_cgn_metadata[\n",
    "#         (df_cgn_metadata.duration_s > 19)\n",
    "#         & (df_cgn_metadata.component.isin(valid_components))\n",
    "#         # & (df_cgn_metadata.dop == 'unscripted')\n",
    "#     ]\n",
    "#     .sample(1)\n",
    "#     .iloc[0],\n",
    "#     margin_s=-2,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cgn_metadata[df_cgn_metadata.duration_s > 15].groupby(\n",
    "#     [\n",
    "#         \"text_type\",\n",
    "#         \"dop\",\n",
    "#         \"mode\",\n",
    "#         \"domain\",\n",
    "#         \"country\"\n",
    "#     ]\n",
    "# ).size().rename(\"#segments\").to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract opensmile features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_parse_smile_duration(\n",
    "    s: opensmile.Smile, uuid_str, wav_path: Path, start_s: float, end_s: float\n",
    ") -> pd.DataFrame:\n",
    "    wav_arr, _ = torchaudio.load(wav_path)\n",
    "    wav_arr = wav_arr.numpy().ravel()\n",
    "    sr = 16_000\n",
    "\n",
    "    df_feat = s.process_signal(\n",
    "        signal=wav_arr,\n",
    "        sampling_rate=sr,\n",
    "        file=str(wav_path),\n",
    "        start=start_s,\n",
    "        end=end_s,\n",
    "    )\n",
    "\n",
    "    df_feat = df_feat.reset_index(drop=False)\n",
    "    df_feat[\"file\"] = df_feat[\"file\"].astype(str)\n",
    "    df_feat[\"uuid\"] = uuid_str\n",
    "    return df_feat\n",
    "\n",
    "\n",
    "def _extract_opensmile_f_duration(file_start_end_uuid) -> Tuple[pd.DataFrame, ...]:\n",
    "    file, start, end, uuid_str = file_start_end_uuid\n",
    "    # calculate the global utterance features\n",
    "    return (\n",
    "        _extract_parse_smile_duration(\n",
    "            func_gemaps, wav_path=file, uuid_str=uuid_str, start_s=start, end_s=end\n",
    "        ),\n",
    "        # _extract_parse_smile_duration(\n",
    "        #     func_compare, arr_path=file, start_s=start, end_s=end\n",
    "        # ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e384ec66049c468c815b03583d67bda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = (df_cgn_metadata.duration_s > (min_duration_s + margin_s * 2)) & (\n",
    "    df_cgn_metadata.component.isin(valid_components)\n",
    ")\n",
    "\n",
    "wav_file_start_end_uuid: List[Tuple[Path, float, float, str]] = []\n",
    "for _, row in tqdm(df_cgn_metadata[mask].iterrows(), total=mask.sum()):\n",
    "    recording_name = None\n",
    "    for c in [\"rec_name\", \"recordingID\"]:\n",
    "        if c in row:\n",
    "            recording_name = row[c]\n",
    "            break\n",
    "    assert recording_name is not None\n",
    "\n",
    "    # Load the audio data\n",
    "    # TODO -> i think this glob is really slow\n",
    "    file_path = list(\n",
    "        cgn_root_dir.glob(f\"cdroms/comp-{row.component}/*/{recording_name}.wav\")\n",
    "    )\n",
    "    assert len(file_path) == 1\n",
    "\n",
    "    t_start = row.t_start + margin_s\n",
    "    t_end = row.t_stop - margin_s\n",
    "\n",
    "\n",
    "    delta = (t_end - t_start) - min_duration_s\n",
    "    # if delta > 1:\n",
    "    #     # randint = np.random.randint(0, 1000 * delta)\n",
    "    #     # offset = randint / 1000\n",
    "    #     delta = (t_end - t_start) - min_duration_s\n",
    "    t_start += delta\n",
    "\n",
    "    wav_file_start_end_uuid.append(\n",
    "        (file_path[0], t_start, t_start + min_duration_s, row.uuid)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb96e87e82e840afaf081f0b7c396693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out: List = []\n",
    "with Pool(processes=8) as pool:\n",
    "    results = pool.imap_unordered(_extract_opensmile_f_duration, wav_file_start_end_uuid)\n",
    "    results = tqdm(results, total=len(wav_file_start_end_uuid))\n",
    "    try:\n",
    "        out = [f for f in results]\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        pool.terminate()\n",
    "    finally:\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "df_gemaps_func_dur_start = pd.concat([o[0] for o in out], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gemaps_func_dur_start_m = df_gemaps_func_dur_start.merge(\n",
    "    df_cgn_metadata, on=\"uuid\", how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gemaps_func_dur_start_m.to_parquet(\n",
    "    loc_data_dir / \"df_gemaps_cgn_15s_end.parquet\", engine=\"fastparquet\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gssp-27YL4uf1-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
